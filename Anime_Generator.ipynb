{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anime_Generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/eemanmajumder/the-anime-dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LDziy681qsA",
        "outputId": "2f1d5921-7a1a-4a16-e241-72997436efeb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.63.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: eemanmajumder\n",
            "Your Kaggle Key: ··········\n",
            "Downloading the-anime-dataset.zip to ./the-anime-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.17M/3.17M [00:00<00:00, 159MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WihkJ9X9rrhW",
        "outputId": "3f283d75-766d-4697-a63f-a8bac02eccfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from spacy.tokenizer import Tokenizer\n",
        "from spacy.lang.en import English\n",
        "import torch\n",
        "import spacy\n",
        "nlp = English()\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "pd.options.display.max_columns = 500\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('eda-data.csv',index_col=0)\n",
        "synopsis = data.synopsis\n",
        "print('Number of Anime synopsis we have: ',len(synopsis))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfnPAtuesCRf",
        "outputId": "10efc464-734b-4902-b02e-be0739e0d69e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Anime synopsis we have:  16610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = random.randint(0,len(synopsis))\n",
        "print('Synopsis example\\n\\nAnime:{} \\nSynopsis:{}\\n'.format(data['anime_name'].values[i],synopsis.values[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEiPGR7wsGfk",
        "outputId": "52299374-d8a5-4539-d318-d515b6cbc06a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synopsis example\n",
            "\n",
            "Anime:Flanders no Inu, Boku no Patrasche \n",
            "Synopsis:A boy named Nello becomes an orphan at the age of two when his mother dies.  His grandfather, who lives in a small village takes him in. One day, Nello finds a dog who was almost beaten to death and named him Patrasche. Due to the good care of his grandfather, the dog recovers, and from then on, Nello and Patrasche are inseparable. Since they are very poor, Nello has to help his grandfather by selling milk. Patrasche helps him pull the milk cart that Nello uses to sell milk in the town.(Source: Wikipedia)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_source(text):\n",
        "    cln_text = text\n",
        "    if '(Source' in cln_text:\n",
        "        cln_text,_,_ = cln_text.partition('(Source')\n",
        "    elif '[Written ' in cln_text:\n",
        "        cln_text,_,_ = cln_text.partition('[Written')\n",
        "        \n",
        "    return cln_text"
      ],
      "metadata": {
        "id": "JhXJ0DRVsNzc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_synopsis(data):\n",
        "    # removing hentai and kids tags\n",
        "    data = data[(data.Hentai != 1) & (data.Kids != 1)]\n",
        "    synopsis = data.synopsis\n",
        "    \n",
        "    # removing very small synopsis\n",
        "    synopsis = synopsis.apply(lambda x: x if ((len(str(x).strip().split())<=300) and len(str(x).strip().split())>30  ) else -1)\n",
        "    synopsis = synopsis[synopsis!=-1]\n",
        "    \n",
        "    # removing source text\n",
        "    synopsis = synopsis.apply(lambda x: remove_source(x))\n",
        "    \n",
        "    # removing japanese characters\n",
        "    synopsis = synopsis.apply(lambda x: re.sub(\"([^\\x00-\\x7F])+\",\" \",x))\n",
        "    \n",
        "    # remove symbols\n",
        "    rx = re.compile('^[&#/@`)(;<=\\'\"$%>]')\n",
        "    synopsis = synopsis.apply(lambda x: rx.sub('',x))\n",
        "    synopsis = synopsis.apply(lambda x: x.replace('>',\"\"))\n",
        "    synopsis = synopsis.apply(lambda x: x.replace('`',\"\"))\n",
        "    synopsis = synopsis.apply(lambda x: x.replace(')',\"\"))\n",
        "    synopsis = synopsis.apply(lambda x: x.replace('(',\"\"))\n",
        "    \n",
        "\n",
        "    # removing adaptation animes (some relevant might get deleted but there aren`t a lot so we wont be affected as much)\n",
        "    synopsis = synopsis[synopsis.apply(lambda x: 'adaptation' not in str(x).lower())]    \n",
        "    synopsis = synopsis[synopsis.apply(lambda x: 'music video' not in str(x).lower())]\n",
        "    synopsis = synopsis[synopsis.apply(lambda x: 'based on' not in str(x).lower())]\n",
        "    synopsis = synopsis[synopsis.apply(lambda x: 'spin-off' not in str(x).lower())]\n",
        "    \n",
        "    return synopsis.reset_index(drop=True)\n",
        "\n",
        "cleaned_synopsis = clean_synopsis(data)\n",
        "print('Size: ',len(cleaned_synopsis))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9wZvvNpsR2Z",
        "outputId": "f3148222-538c-4473-ab9f-bb47f27d1944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size:  7309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:    \n",
        "    tokenizer = nltk.word_tokenize    \n",
        "    #data = AnimeDataset(cleaned_synopsis)\n",
        "    batch_size = 32\n",
        "    #vocab_size = data.vocab_size\n",
        "    seq_len = 30\n",
        "        \n",
        "    emb_dim = 100\n",
        "    epochs = 15\n",
        "    hidden_dim = 512\n",
        "    model_path = 'lm_lrdecay_drop.bin'"
      ],
      "metadata": {
        "id": "Nq_0QFAusSqQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(synopsis,batch_size,seq_len):\n",
        "    np.random.seed(0)\n",
        "    synopsis = synopsis.apply(lambda x: str(x).lower()).values\n",
        "    synopsis_text = ' '.join(synopsis)\n",
        "    \n",
        "    \n",
        "    tokens = config.tokenizer(synopsis_text)\n",
        "    global num_batches\n",
        "    num_batches = int(len(tokens)/(seq_len*batch_size))\n",
        "    tokens = tokens[:num_batches*batch_size*seq_len]\n",
        "    \n",
        "    words = sorted(set(tokens))        \n",
        "    w2i = {w:i for i,w in enumerate(words)}\n",
        "    i2w = {i:w for i,w in enumerate(words)}\n",
        "    \n",
        "    tokens = [w2i[tok] for tok in tokens]\n",
        "    target = np.zeros_like((tokens))\n",
        "    target[:-1] = tokens[1:]\n",
        "    target[-1] = tokens[0]\n",
        "    \n",
        "    input_tok = np.reshape(tokens,(batch_size,-1))\n",
        "    target_tok = np.reshape(target,(batch_size,-1))\n",
        "    \n",
        "    print(input_tok.shape)\n",
        "    print(target_tok.shape)\n",
        "    \n",
        "    vocab_size = len(i2w)\n",
        "    return input_tok,target_tok,vocab_size,w2i,i2w\n",
        "\n",
        "def create_batches(input_tok,target_tok,batch_size,seq_len):\n",
        "    \n",
        "    num_batches = np.prod(input_tok.shape)//(batch_size*seq_len)\n",
        "    \n",
        "    for i in range(0,num_batches*seq_len,seq_len):\n",
        "        yield input_tok[:,i:i+seq_len], target_tok[:,i:i+seq_len]\n",
        "               "
      ],
      "metadata": {
        "id": "0E6IZEyosVlS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):    \n",
        "    def __init__(self,hid_dim,emb_dim,vocab_size,num_layers=1):\n",
        "        super(LSTMModel,self).__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.vocab_size = vocab_size+1\n",
        "        self.embedding = nn.Embedding(self.vocab_size,self.emb_dim)\n",
        "        self.lstm = nn.LSTM(self.emb_dim,self.hid_dim,batch_first = True,num_layers = self.num_layers)\n",
        "        self.drop = nn.Dropout(0.3)\n",
        "        self.linear = nn.Linear(self.hid_dim,vocab_size) # from here we will randomly sample a word\n",
        "        \n",
        "    def forward(self,x,prev_hid):\n",
        "        x = self.embedding(x)\n",
        "        x,hid = self.lstm(x,prev_hid)\n",
        "        x = self.drop(x)\n",
        "        x = self.linear(x)\n",
        "        return x,hid\n",
        "    \n",
        "    def zero_state(self,batch_size):\n",
        "        return (torch.zeros(self.num_layers,batch_size,self.hid_dim),torch.zeros(self.num_layers,batch_size,self.hid_dim))"
      ],
      "metadata": {
        "id": "sJAl1xn1saEw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "-LWoTuK3sgoO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(predicted,target):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    return loss(predicted,target)"
      ],
      "metadata": {
        "id": "Orz9PpNysli9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(model,device,dataloader,optimizer):\n",
        "    model.train()\n",
        "    tk0 = tqdm(dataloader,position=0,leave=True,total = num_batches)\n",
        "    train_loss = AverageMeter()  \n",
        "    hid_state,cell_state = model.zero_state(config.batch_size)\n",
        "    hid_state = hid_state.to(device)\n",
        "    cell_state = cell_state.to(device)\n",
        "    losses = []\n",
        "    for inp,target in tk0:\n",
        "                \n",
        "        inp = torch.tensor(inp,dtype=torch.long).to(device)\n",
        "        target = torch.tensor(target,dtype=torch.long).to(device)\n",
        "\n",
        "        optimizer.zero_grad()        \n",
        "        pred,(hid_state,cell_state) = model(inp,(hid_state,cell_state))\n",
        "        #print(pred.transpose(1,2).shape)\n",
        "        \n",
        "        loss = loss_fn(pred.transpose(1,2),target)\n",
        "        \n",
        "        hid_state = hid_state.detach()\n",
        "        cell_state = cell_state.detach()\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        _ = torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=2) # to avoid gradient explosion\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.update(loss.detach().item())\n",
        "        tk0.set_postfix(loss = train_loss.avg)\n",
        "        losses.append(loss.detach().item())\n",
        "    return np.mean(losses)"
      ],
      "metadata": {
        "id": "nNzkJpfusp6-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tok,target_tok,vocab_size,w2i,i2w = create_dataset(cleaned_synopsis,batch_size=config.batch_size,seq_len=config.seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0n7rG71sqmK",
        "outputId": "49b9656c-61a5-4242-fa20-a23c9373d57c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 25380)\n",
            "(32, 25380)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run():\n",
        "    device = 'cuda'\n",
        "    model = LSTMModel(vocab_size=vocab_size,emb_dim=config.emb_dim,hid_dim=config.hidden_dim,num_layers=3).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode = 'min', patience=2, verbose=True, factor=0.5)\n",
        "    epochs = config.epochs\n",
        "    \n",
        "    best_loss = 999\n",
        "    for i in range(1,epochs+1):\n",
        "        train_dataloader = create_batches(batch_size=config.batch_size,input_tok=input_tok,seq_len=config.seq_len,target_tok=target_tok)\n",
        "        print('Epoch..',i)\n",
        "        loss = train_fn(model,device,train_dataloader,optimizer)\n",
        "        if loss<best_loss:\n",
        "            best_loss = loss\n",
        "            torch.save(model.state_dict(),config.model_path)\n",
        "        scheduler.step(loss)\n",
        "        torch.cuda.empty_cache()\n",
        "    return model"
      ],
      "metadata": {
        "id": "OUT5t7Mgst9q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-F3YAB-s18f",
        "outputId": "a42215b2-1b7c-46ca-909a-a637742e2e71"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:52<00:00,  7.55it/s, loss=7.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:55<00:00,  7.32it/s, loss=6.54]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:57<00:00,  7.18it/s, loss=6.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.16it/s, loss=5.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.16it/s, loss=5.58]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.17it/s, loss=5.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.16it/s, loss=5.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.16it/s, loss=5.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.16it/s, loss=4.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.16it/s, loss=4.74]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.17it/s, loss=4.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.17it/s, loss=4.48]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:58<00:00,  7.17it/s, loss=4.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:57<00:00,  7.17it/s, loss=4.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch.. 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 846/846 [01:57<00:00,  7.17it/s, loss=4.16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model,input_text,device,top_k=5,length = 100):\n",
        "    output = ''\n",
        "    model.eval()\n",
        "    tokens = config.tokenizer(input_text)\n",
        "        \n",
        "    h,c = model.zero_state(1)\n",
        "    h = h.to(device)\n",
        "    c = c.to(device)\n",
        "    \n",
        "    for t in tokens:\n",
        "        output = output+t+' '\n",
        "        pred,(h,c) = model(torch.tensor(w2i[t.lower()]).view(1,-1).to(device),(h,c))\n",
        "        #print(pred.shape)\n",
        "    for i in range(length):\n",
        "        _,top_ix = torch.topk(pred[0],k = top_k)\n",
        "               \n",
        "        choices = top_ix[0].tolist()                \n",
        "        choice = np.random.choice(choices)\n",
        "        out = i2w[choice]\n",
        "        output = output + out + ' '\n",
        "        pred,(h,c) = model(torch.tensor(choice,dtype=torch.long).view(1,-1).to(device),(h,c))\n",
        "    return output"
      ],
      "metadata": {
        "id": "9w7kcU9As5az"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "mod = LSTMModel(emb_dim=config.emb_dim,hid_dim=config.hidden_dim,vocab_size=vocab_size,num_layers=3).to(device)\n",
        "mod.load_state_dict(torch.load(config.model_path))\n",
        "print('AI generated Anime synopsis:')\n",
        "inference(model = mod, input_text = 'Bob the Architect  ', top_k = 30, length = 1000, device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "gywEtnIIs6KK",
        "outputId": "7e06b063-87f1-45ac-cb20-a326a3c2a2d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI generated Anime synopsis:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Bob the Architect in this series ; '' he finds how many friends about and falls along when demons must show it at any time with a mysterious young man she gets up , while dealing in his new lives ... as such he is transported a secret where these kids can seem for an entire ally.years before this . despite completing another life when you must find an old quest that was just an energetic stall.though the wrestling world to its serialization ... at st. 's past academy during class and finds the message 's lair from this unusual enemy for a life she was told out when he finds his friends ; one after him after something about more from being known until `` mcfat ... as there means you ... is the smartest , athletic school worker whose son s wife will now watch any new treasure for those ' `` i would survive together with something it wo expected his way true : his family for an uncanny kurta spirit who goes at the sky by any eccentric bread at school city usually called texhnolyze and becomes some and exorcists the one is never smooth because that they 're . and one girl has his way . when she goes from on him that was found during his class . she comes across her own . dazed ayase brane follows all three youths called the ypserlon king . `` there may know this for having fun as six as more confusion.one president of its life semmerling a boy named `` dragon : z city -- that does seen your . however ! one last of this situation a girl ? with many days called roles : director goku , ishii is sent from another new semester . these youths who had an elite range but and she and hina . he wants to leave , kain no a group but , is caught up when someone can also be quite at `` why you , in love and becomes popular to their true relationship as the girls separating each the youngsters from an iron planet ' death ... what can something one is in reality is to face something with something or will no other in need , they do always actually make what we would get too for you on all sorts from her mammaries and his heart in order at koshien a man ' high world and is stolen from mt ? vash city the game s main stories also released at january rankings at first than another , in reality they need through a small reality series '' where hachiman had diablo during , while the young world 's police race for this epilogue ! it follows his name who takes their appearance of life around their family as one too while with an end and unwittingly to save her , to her family s heart , turning him on and leaves a crudely-made world where he has left it ... in it to prepare of nowhere as no `` his school . he writes , to go together . and now her new companion : weda comes to him where there s all that more to one student at midnight . a little time ! , she 's supposed through the attention such when he leaves himself with no kind ; tatsumi instead he finds one girl as usual to become possible of other days she 's so , until as many months that can make an assignment : mcdull must cope and face her that of him from becoming human days or ... he is about on all a small town 's day after he discovers something it can turn her true identity when as this was easier or he goes missing without being his grandfather . one day they become an excellent model critic that wants they live by that the world can live as in a desperate greater situation ? one years at `` future : tension `` '' will appear between humans known at them in their daily journey a sudden battle , they become many powerful types known together in isolation after those on nhk in order with her older lover in another century ; when henriette are a mysterious member to an abrupt year schedule before many people to his past ; rion the twins of kyoto 's zip as an event engineer - coming the entire life 's symbol `` and why should all allow them when kouji finds this of school . however for another bizarre boy called challengers known from these warriors , who runs on that island are going about it from any one who should become well of any one would kill as well on earth ! in one and mysterious time comes across in search goku at his home school and at its age a high love factory before they do an appropriate life in an event . there is some time she loves during nothing in 1983 prefecture s training company with two riots because their little friends for any more time . mcdull 's old reputation . at an endless future . to complicate no death if he was one 's normal , his former sidekick nikaidou suddenly discovers his journey . his childhood mother tetsuo 's family had n't really , is at his hands about youko ; in his wake locker at his mind by signing that that means `` gantz god 2 ... which , where his best one can only get involved at an intergalactic space factory for them . when genjo beings are made over him ! an unexpected earthquake with their name being about more by being any . however ... ! my father changes an uneasy in an odd artifact from it a journey across an odd demand on with these four groups are drawn with any more visitors ! it turns around for \""
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}